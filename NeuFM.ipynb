{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NeuFM.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "RpcgJwXhVwuM",
        "3sPXfslv_zW4"
      ],
      "authorship_tag": "ABX9TyN/m1jWHg/QRaM6mAcGkUKj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/van26101998/Recommendation-System/blob/main/NeuFM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4kQBE6orBph9"
      },
      "source": [
        "# Install and import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tAOXZ9XZSPBE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "763f0105-7ec5-4715-ae87-aa790dc853c4"
      },
      "source": [
        "# install required packages\r\n",
        "!pip install -q comet_ml wandb"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 245kB 4.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.8MB 53.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 204kB 56.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 512kB 55.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 81kB 11.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 163kB 55.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 133kB 59.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 102kB 13.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 71kB 8.7MB/s \n",
            "\u001b[?25h  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for configobj (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        },
        "id": "KidjilA-SRFc",
        "outputId": "a568888f-21e9-4671-b540-243fc00984eb"
      },
      "source": [
        "import wandb\r\n",
        "wandb_run = wandb.init(project=\"neumf\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Tracking run with wandb version 0.10.12<br/>\n",
              "                Syncing run <strong style=\"color:#cdcd00\">dashing-vortex-20</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://wandb.ai/van26101998/neumf\" target=\"_blank\">https://wandb.ai/van26101998/neumf</a><br/>\n",
              "                Run page: <a href=\"https://wandb.ai/van26101998/neumf/runs/136hpkkt\" target=\"_blank\">https://wandb.ai/van26101998/neumf/runs/136hpkkt</a><br/>\n",
              "                Run data is saved locally in <code>/content/wandb/run-20210108_091502-136hpkkt</code><br/><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jSi4tAzq_xkc"
      },
      "source": [
        "from typing import List, Dict, Text\r\n",
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F\r\n",
        "from torch.utils.data import DataLoader, Dataset, Subset\r\n",
        "\r\n",
        "from torchsummary import summary\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import zipfile\r\n",
        "import random\r\n",
        "\r\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RpcgJwXhVwuM"
      },
      "source": [
        "# Movielens 1M Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pFz80uYndbKA",
        "outputId": "adec01af-fe9a-4f33-876b-e61cf822a0ff"
      },
      "source": [
        "!wget -c http://files.grouplens.org/datasets/movielens/ml-1m.zip\r\n",
        "import zipfile\r\n",
        "with zipfile.ZipFile('ml-1m.zip', 'r') as zip_ref:\r\n",
        "    zip_ref.extractall()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-01-08 09:15:06--  http://files.grouplens.org/datasets/movielens/ml-1m.zip\n",
            "Resolving files.grouplens.org (files.grouplens.org)... 128.101.65.152\n",
            "Connecting to files.grouplens.org (files.grouplens.org)|128.101.65.152|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5917549 (5.6M) [application/zip]\n",
            "Saving to: ‘ml-1m.zip’\n",
            "\n",
            "ml-1m.zip           100%[===================>]   5.64M  4.28MB/s    in 1.3s    \n",
            "\n",
            "2021-01-08 09:15:08 (4.28 MB/s) - ‘ml-1m.zip’ saved [5917549/5917549]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "XjjA0peCTfaZ",
        "outputId": "702d71bc-6ca1-4c6a-ddfa-25af22772e2a"
      },
      "source": [
        "ratings_df = pd.read_csv('./ml-1m/ratings.dat', sep=\"::\", engine='python', names=['user', 'item', 'rating', 'timestamp'])\r\n",
        "users = sorted(ratings_df['user'].unique())\r\n",
        "items = sorted(ratings_df['item'].unique())\r\n",
        "ratings_df"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user</th>\n",
              "      <th>item</th>\n",
              "      <th>rating</th>\n",
              "      <th>timestamp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1193</td>\n",
              "      <td>5</td>\n",
              "      <td>978300760</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>661</td>\n",
              "      <td>3</td>\n",
              "      <td>978302109</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>914</td>\n",
              "      <td>3</td>\n",
              "      <td>978301968</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>3408</td>\n",
              "      <td>4</td>\n",
              "      <td>978300275</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>2355</td>\n",
              "      <td>5</td>\n",
              "      <td>978824291</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1000204</th>\n",
              "      <td>6040</td>\n",
              "      <td>1091</td>\n",
              "      <td>1</td>\n",
              "      <td>956716541</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1000205</th>\n",
              "      <td>6040</td>\n",
              "      <td>1094</td>\n",
              "      <td>5</td>\n",
              "      <td>956704887</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1000206</th>\n",
              "      <td>6040</td>\n",
              "      <td>562</td>\n",
              "      <td>5</td>\n",
              "      <td>956704746</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1000207</th>\n",
              "      <td>6040</td>\n",
              "      <td>1096</td>\n",
              "      <td>4</td>\n",
              "      <td>956715648</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1000208</th>\n",
              "      <td>6040</td>\n",
              "      <td>1097</td>\n",
              "      <td>4</td>\n",
              "      <td>956715569</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000209 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         user  item  rating  timestamp\n",
              "0           1  1193       5  978300760\n",
              "1           1   661       3  978302109\n",
              "2           1   914       3  978301968\n",
              "3           1  3408       4  978300275\n",
              "4           1  2355       5  978824291\n",
              "...       ...   ...     ...        ...\n",
              "1000204  6040  1091       1  956716541\n",
              "1000205  6040  1094       5  956704887\n",
              "1000206  6040   562       5  956704746\n",
              "1000207  6040  1096       4  956715648\n",
              "1000208  6040  1097       4  956715569\n",
              "\n",
              "[1000209 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YN7eFrMtU0Gy"
      },
      "source": [
        "# train validate test split\r\n",
        "train_df, test_df = train_test_split(ratings_df, test_size=0.1)\r\n",
        "train_df, validate_df = train_test_split(train_df, test_size=0.1)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YoMoTusznlCp",
        "outputId": "3f716c56-a297-4739-a338-08b8f7657fef"
      },
      "source": [
        "print(\"number of train-validate-test:\", len(train_df), len(validate_df), len(test_df))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of train-validate-test: 810169 90019 100021\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EK40qPN2dbtA"
      },
      "source": [
        "class ML1MDataset(Dataset):\r\n",
        "    \"\"\"\r\n",
        "        MovieLens 1M Dataset\r\n",
        "        + Params:\r\n",
        "            - ratings_df: DataFrame with 4 columns: user, item, rating, timestamp\r\n",
        "            - users: list all users\r\n",
        "            - items: list all items\r\n",
        "    \"\"\"\r\n",
        "    def __init__(self, ratings_df: pd.DataFrame, users: List[int], items: List[int]): \r\n",
        "        \r\n",
        "        self.data = ratings_df.to_numpy()\r\n",
        "        \r\n",
        "        self.users = users\r\n",
        "        self.items = items\r\n",
        "        \r\n",
        "        self.num_users = len(self.users)\r\n",
        "        self.num_items = len(self.items)\r\n",
        "\r\n",
        "        self.features_dim = self.num_users + self.num_items\r\n",
        "\r\n",
        "        self.user_to_id = {user:id for id, user in enumerate(self.users)}\r\n",
        "        self.item_to_id = {item:id for id, item in enumerate(self.items)}\r\n",
        "    \r\n",
        "    def __len__(self):\r\n",
        "        return len(self.data)\r\n",
        "    \r\n",
        "\r\n",
        "    def __getitem__(self, idx):\r\n",
        "        \"\"\"\r\n",
        "        Returns:\r\n",
        "            + feature: a LongTensor, concatenate onehot vectors of user and item\r\n",
        "            + target: a FloatTensor, is a rating of user to item\r\n",
        "        \"\"\"\r\n",
        "        user, item, rating, timestamp = self.data[idx]\r\n",
        "\r\n",
        "        user_id = self.user_to_id[user]\r\n",
        "        item_id = self.item_to_id[item]\r\n",
        "\r\n",
        "        features = np.array([user_id, item_id + self.num_items])\r\n",
        "        feature_values = np.array([1.0, 1.0], dtype=np.float32)\r\n",
        "        target = np.float32(rating)\r\n",
        "\r\n",
        "        # features = torch.LongTensor([[user_id], [item_id + self.num_items]])\r\n",
        "        # feature_values = torch.FloatTensor([[1.0], [1.0]])\r\n",
        "        # target = torch.FloatTensor([float(rating)])\r\n",
        "        \r\n",
        "        return features, feature_values, target"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cy4_nulOhaec"
      },
      "source": [
        "trainset =  ML1MDataset(train_df, users, items)\r\n",
        "testset = ML1MDataset(test_df, users, items)\r\n",
        "validateset = ML1MDataset(validate_df, users, items)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CZWnFea2OJ23",
        "outputId": "c5820fa6-de4b-4d90-b791-f7af528f7a6e"
      },
      "source": [
        "trainset[0]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([4226, 6148]), array([1., 1.], dtype=float32), 3.0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3sPXfslv_zW4"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_Ydasr4-XHR"
      },
      "source": [
        "class NFM(nn.Module):\r\n",
        "    def __init__(self, num_features, num_factors, \r\n",
        "        act_function, layers, batch_norm, drop_prob, pretrain_FM):\r\n",
        "        super(NFM, self).__init__()\r\n",
        "        \"\"\"\r\n",
        "        num_features: number of features,\r\n",
        "        num_factors: number of hidden factors,\r\n",
        "        act_function: activation function for MLP layer,\r\n",
        "        layers: list of dimension of deep layers,\r\n",
        "        batch_norm: bool type, whether to use batch norm or not,\r\n",
        "        drop_prob: list of the dropout rate for FM and MLP,\r\n",
        "        pretrain_FM: the pre-trained FM weights.\r\n",
        "        \"\"\"\r\n",
        "        self.num_features = num_features\r\n",
        "        self.num_factors = num_factors\r\n",
        "        self.act_function = act_function\r\n",
        "        self.layers = layers\r\n",
        "        self.batch_norm = batch_norm\r\n",
        "        self.drop_prob = drop_prob\r\n",
        "        self.pretrain_FM = pretrain_FM\r\n",
        "\r\n",
        "        self.embeddings = nn.Embedding(num_features, num_factors)\r\n",
        "        self.biases = nn.Embedding(num_features, 1)\r\n",
        "        self.bias_ = nn.Parameter(torch.tensor([0.0]))\r\n",
        "\r\n",
        "        FM_modules = []\r\n",
        "        if self.batch_norm:\r\n",
        "            FM_modules.append(nn.BatchNorm1d(num_factors))      \r\n",
        "        FM_modules.append(nn.Dropout(drop_prob[0]))\r\n",
        "        self.FM_layers = nn.Sequential(*FM_modules)\r\n",
        "\r\n",
        "        MLP_module = []\r\n",
        "        in_dim = num_factors\r\n",
        "        for dim in self.layers:\r\n",
        "            out_dim = dim\r\n",
        "            MLP_module.append(nn.Linear(in_dim, out_dim))\r\n",
        "            in_dim = out_dim\r\n",
        "\r\n",
        "            if self.batch_norm:\r\n",
        "                MLP_module.append(nn.BatchNorm1d(out_dim))\r\n",
        "            if self.act_function == 'relu':\r\n",
        "                MLP_module.append(nn.ReLU())\r\n",
        "            elif self.act_function == 'sigmoid':\r\n",
        "                MLP_module.append(nn.Sigmoid())\r\n",
        "            elif self.act_function == 'tanh':\r\n",
        "                MLP_module.append(nn.Tanh())\r\n",
        "\r\n",
        "            MLP_module.append(nn.Dropout(drop_prob[-1]))\r\n",
        "        self.deep_layers = nn.Sequential(*MLP_module)\r\n",
        "\r\n",
        "        predict_size = layers[-1] if layers else num_factors\r\n",
        "        self.prediction = nn.Linear(predict_size, 1, bias=False)\r\n",
        "\r\n",
        "        self._init_weight_()\r\n",
        "\r\n",
        "    def _init_weight_(self):\r\n",
        "        \"\"\" Try to mimic the original weight initialization. \"\"\"\r\n",
        "        if self.pretrain_FM:\r\n",
        "            self.embeddings.weight.data.copy_(\r\n",
        "                            self.pretrain_FM.embeddings.weight)\r\n",
        "            self.biases.weight.data.copy_(\r\n",
        "                            self.pretrain_FM.biases.weight)\r\n",
        "            self.bias_.data.copy_(self.pretrain_FM.bias_)\r\n",
        "        else:\r\n",
        "            nn.init.normal_(self.embeddings.weight, std=0.01)\r\n",
        "            nn.init.constant_(self.biases.weight, 0.0)\r\n",
        "\r\n",
        "        # for deep layers\r\n",
        "        if len(self.layers) > 0:\r\n",
        "            for m in self.deep_layers:\r\n",
        "                if isinstance(m, nn.Linear):\r\n",
        "                    nn.init.xavier_normal_(m.weight)\r\n",
        "            nn.init.xavier_normal_(self.prediction.weight)\r\n",
        "        else:\r\n",
        "            nn.init.constant_(self.prediction.weight, 1.0)\r\n",
        "\r\n",
        "    def forward(self, features, feature_values):\r\n",
        "        nonzero_embed = self.embeddings(features)\r\n",
        "        feature_values = feature_values.unsqueeze(dim=-1)\r\n",
        "        nonzero_embed = nonzero_embed * feature_values\r\n",
        "\r\n",
        "        # Bi-Interaction layer\r\n",
        "        sum_square_embed = nonzero_embed.sum(dim=1).pow(2)\r\n",
        "        square_sum_embed = (nonzero_embed.pow(2)).sum(dim=1)\r\n",
        "\r\n",
        "        # FM model\r\n",
        "        FM = 0.5 * (sum_square_embed - square_sum_embed)\r\n",
        "        FM = self.FM_layers(FM)\r\n",
        "        if self.layers: # have deep layers\r\n",
        "            FM = self.deep_layers(FM)\r\n",
        "        FM = self.prediction(FM)\r\n",
        "\r\n",
        "        # bias addition\r\n",
        "        feature_bias = self.biases(features)\r\n",
        "        feature_bias = (feature_bias * feature_values).sum(dim=1)\r\n",
        "        FM = FM + feature_bias + self.bias_\r\n",
        "        return FM.view(-1)\r\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tFgIzp_-Bl3A"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V4gI_JujEeAE"
      },
      "source": [
        "def train(model, trainloader, optimizer, device):\r\n",
        "    model.train()\r\n",
        "    mse = 0.0\r\n",
        "    num_datapoints = len(trainloader.dataset)\r\n",
        "\r\n",
        "    for features, feature_values, target in trainloader:\r\n",
        "        features = features.to(device)\r\n",
        "        feature_values = feature_values.to(device)\r\n",
        "        target = target.to(device)\r\n",
        "\r\n",
        "        model.zero_grad() \r\n",
        "        prediction = model(features, feature_values) \r\n",
        "        loss = nn.MSELoss(reduction='sum')(prediction, target) \r\n",
        "        loss += lamda * model.embeddings.weight.norm() \r\n",
        "        loss.backward() \r\n",
        "        optimizer.step() \r\n",
        "        \r\n",
        "        mse += loss.item() / num_datapoints\r\n",
        "    \r\n",
        "    return mse\r\n",
        "\r\n",
        "    \r\n",
        "  "
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YNPRnXEvGK7h"
      },
      "source": [
        "def test(model, testloader, device):\r\n",
        "    model.eval()\r\n",
        "    # mse = 0.0\r\n",
        "    # num_datapoints = len(testloader.dataset)\r\n",
        "    RMSE = np.array([], dtype=np.float32)\r\n",
        "    for features, feature_values, target in testloader:\r\n",
        "        features = features.to(device)\r\n",
        "        feature_values = feature_values.to(device)\r\n",
        "        target = target.to(device)\r\n",
        "\r\n",
        "        prediction = model(features, feature_values) \r\n",
        "        prediction = prediction.clamp(min=1.0, max=5.0) \r\n",
        "        \r\n",
        "        SE = (prediction - target).pow(2) \r\n",
        "        # mse += se.item() / num_datapoints\r\n",
        "        RMSE = np.append(RMSE, SE.detach().cpu().numpy())\r\n",
        "        \r\n",
        "    return np.sqrt(RMSE.mean()) #RMSE"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q9CT6RZe-pAG"
      },
      "source": [
        "num_features = trainset.features_dim # num users + num items\r\n",
        "num_factors = 64 # hidden factor\r\n",
        "act_function = 'relu'\r\n",
        "layers = [64]\r\n",
        "batch_norm = True\r\n",
        "drop_prob = [0.5, 0.2]\r\n",
        "pretrain_FM = False\r\n",
        "\r\n",
        "\r\n",
        "lamda = 1e-6\r\n",
        "lr = 0.001\r\n",
        "batch_size = 512\r\n",
        "epochs = 100\r\n",
        "device = torch.device('cuda')\r\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J9V2GTYZ_KFg"
      },
      "source": [
        "model = NFM(num_features, num_factors, act_function, layers, batch_norm, drop_prob, pretrain_FM)\r\n",
        "model = model.to(device)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jtuOxIr2Sbrl",
        "outputId": "479ab3e5-ed1b-4035-c530-ca714314909d"
      },
      "source": [
        "wandb.watch(model, log=\"all\")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<wandb.wandb_torch.TorchGraph at 0x7f49b0554208>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wa_wMISwD-Uz"
      },
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=0.000001)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pOnR5Of5SgDD"
      },
      "source": [
        "params = {\r\n",
        "    \"num_features\": num_features,\r\n",
        "    \"num_factors\": num_factors,\r\n",
        "    \"act_function\": act_function,\r\n",
        "    \"layers\": layers,\r\n",
        "    \"batch_norm\": batch_norm,\r\n",
        "    \"drop_prob\": drop_prob,\r\n",
        "    \"pretrain_FM\": pretrain_FM,\r\n",
        "    \"lamda\": lamda,\r\n",
        "    \"lr\": lr,\r\n",
        "    \"batch_size\": batch_size,\r\n",
        "    \"epochs\": epochs,\r\n",
        "    \"optimizer\": optimizer,\r\n",
        "}\r\n",
        "wandb.config.update(params)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PFCVWCz8H1kI"
      },
      "source": [
        "trainloader = DataLoader(trainset, batch_size=batch_size)\r\n",
        "validateloader = DataLoader(validateset, batch_size=batch_size)\r\n",
        "testloader = DataLoader(testset, batch_size=batch_size)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DtxuX1jlHpQ8",
        "outputId": "f27a1ab4-8411-4e1d-b713-26096c33c3d5"
      },
      "source": [
        "from time import time\r\n",
        "t0 = time()\r\n",
        "\r\n",
        "for epoch in range(epochs):\r\n",
        "    train_loss = train(model, trainloader, optimizer, device)\r\n",
        "    train_rmse = test(model, trainloader, device)\r\n",
        "    valid_rmse = test(model, validateloader, device)\r\n",
        "\r\n",
        "    print('epoch {} \\t train_loss {} \\t train_rmse {} \\t valid_rmse {}'.format(epoch+1, train_loss, train_rmse, valid_rmse))\r\n",
        "\r\n",
        "    metrics = {\r\n",
        "        \"train_loss\": train_loss,\r\n",
        "        \"train_rmse\": train_rmse,\r\n",
        "        \"valid_rmse\": valid_rmse\r\n",
        "    }\r\n",
        "    wandb.log(metrics, step=epoch+1)\r\n",
        "\r\n",
        "print(\"total time: \", time() - t0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch 1 \t train_loss 1.6900149186274718 \t train_rmse 1.3259941339492798 \t valid_rmse 1.341207504272461\n",
            "epoch 2 \t train_loss 1.072664293821547 \t train_rmse 1.0673645734786987 \t valid_rmse 1.0854594707489014\n",
            "epoch 3 \t train_loss 0.9760961064012592 \t train_rmse 0.9849750399589539 \t valid_rmse 1.0071234703063965\n",
            "epoch 4 \t train_loss 0.9243025610906028 \t train_rmse 0.9511322379112244 \t valid_rmse 0.9767338633537292\n",
            "epoch 5 \t train_loss 0.8844468250207924 \t train_rmse 0.9230720400810242 \t valid_rmse 0.9526275992393494\n",
            "epoch 6 \t train_loss 0.8559193393746739 \t train_rmse 0.9133886694908142 \t valid_rmse 0.9459014534950256\n",
            "epoch 7 \t train_loss 0.8368556482380439 \t train_rmse 0.9057212471961975 \t valid_rmse 0.9431531429290771\n",
            "epoch 8 \t train_loss 0.8209736433891178 \t train_rmse 0.9001116752624512 \t valid_rmse 0.9413273334503174\n",
            "epoch 9 \t train_loss 0.8065626189801666 \t train_rmse 0.8959820866584778 \t valid_rmse 0.9424015879631042\n",
            "epoch 10 \t train_loss 0.7953985908808434 \t train_rmse 0.8936487436294556 \t valid_rmse 0.9438176155090332\n",
            "epoch 11 \t train_loss 0.784055671325524 \t train_rmse 0.8878821134567261 \t valid_rmse 0.9430235028266907\n",
            "epoch 12 \t train_loss 0.775226666522291 \t train_rmse 0.8886093497276306 \t valid_rmse 0.9460235238075256\n",
            "epoch 13 \t train_loss 0.7661626627429192 \t train_rmse 0.8858279585838318 \t valid_rmse 0.94709712266922\n",
            "epoch 14 \t train_loss 0.7578525922225234 \t train_rmse 0.8825117349624634 \t valid_rmse 0.9470527768135071\n",
            "epoch 15 \t train_loss 0.7496498949897196 \t train_rmse 0.8807964324951172 \t valid_rmse 0.948914647102356\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-8Id2RPCKO15"
      },
      "source": [
        "test_rmse = test(model, testloader, device)\r\n",
        "print('test rmse:', test_rmse)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xsMRfigTZkG"
      },
      "source": [
        "wandb.log({\"test_rmse\": test_rmse})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gnzGZF-2Tbki"
      },
      "source": [
        "wandb_run.finish()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}